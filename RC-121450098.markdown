
---
Muhammad Fathir Fadillah\
RC\
121450098\
Three Ways of Storing and Accessing Lots of Images in Python\
<https://realpython.com/storing-images-in-python/>

================================================================


``` python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("C:/Users/mafad/Downloads/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```
outputnya =>\
    (50000, 32, 32, 3)\
    (50000,)

Terdapat banyak cara dalam pengaksesan dan penyimpanan suatu data
khususnya data gambar di Python. Pemrosesan dan pemodelan dari data
gambar mampu dikerjakan oleh library PIL. Dengan bantuan library ini
dimungkinkan pemrosesan hingga ratusan gambar. Namun, peningkatan
banyaknya data tentunya meningkatkan beban kerja algoritma. Algoritma
layaknya CNN mampu membantu menyelesaikan kendala ini. Lebih lanjut,
bagaimana data yang sangat besar ini dimuat untuk dilatih. Dalam
pemrosesan batch tentu akan memakan waktu yang cukup lama sehingga
kurang mangkus.


Setup for Storing Images on Disk



Dalam pengaturan penyimpanan gambar dalam disk dibantu oleh library
pillow, lmdb, dan HDF5.
1.LMDB
Seringkali disebut sebagai \"Lightning Database\" karena kecepatannya da
digunakan dalam memory-mapped files. Mangkusnya LMDB didasari oleh
kemampuannya dalam mengembalikan pointer ke alamat baik keys dan juga
valuenya.
2.HDF5
Yakni Hierarchical Data Format. File HDF disusun oleh tipe objek
datasets dan groups. Datasets merujuk pada larik multidimensi sedangkan
groups teridiri dari datasets atau groups yang lain.
3.Pillow
Library ini berguna untuk menampilkan gambar dan modul yang terdapat di
dalam library ini mampu membuat dan membuat gambar.



``` 
pip install Pillow
pip install h5py
pip install lmdb
```




Storing a single image


Pada tahap ini agregasi antar metode penyimpanan dalam menjalankan
tugasnya untuk baca tulis file dan seberapa konsumsi memori penyimpanan.
Dimisalkan di sini menggunakan datta CIFAR-10



``` python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```
``` python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```
Storing to disk

Akan dimasukkan suatu gambar tunggal yang memorinya berupa larik numpy.
Gambar ini nantinya akan disimpan dalam format .png dan dinamakan
menggunakan id. Larik tadi akan disimpan sebagai fiile csv yang kemudian
ditulis kembali untuk diambil dan ditampilkan labelnya.

``` python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```

Storing to LMDB

Setiap entri yang dicobakan disimpan ke LMDB akan disimpan sebagai
larike byte sehingga setiap gambar punya id uniknya masing-masing dan
valuenya beruoa gambar itu sendiri.

``` python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

``` python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

Karena HDF5 teridiri dari datasets dan groups maka diperlukan setidaknya
2 datasets. Datasets pertama yakni gambar itu sendiri dan yang kedua
adalah metadatanya.

``` python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

Experiment for storing a single image

Dibuat sebuah dictionary yang mencakup 3 teknik penyimpanan gambar

``` python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```
``` python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

outputnya =>
    Method: disk, Time usage: 0.14101860000000244\
    Method: lmdb, Time usage: 0.0030824999999978786\
    Method: hdf5, Time usage: 0.00663929999999624



Kemangkusan waktu hdf5 jauh lebih baik daripada lmdb dan disk karena
waktu yang diperlukan dalam menyimpannya jauh lebih kecil.

Storing Many Images

Sama halnya dengan penyimpanan gambar tunggal, tapi kali ini akan dicoba
untuk banyak gambar

``` python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before â€” but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

Preparating the datasets

Pengujian dilakukan dengan membuat beberapa datasets yang memiliki 10,
100, 1000, 10000, dan 100000 gambar

``` python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

outputnya =>\
    (100000, 32, 32, 3)\
    (100000,)

Datasets berjumlah 100000 dengan ukuran 32 x 32 dan format warna RGB.

Experiment for many images

Sekarang dicoba untuk menyimpan yang lebih banyak lagi

``` python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

outputnya =>\
    Method: disk, Time usage: 0.01748150000000237\
    Method: lmdb, Time usage: 0.003559100000003923\
    Method: hdf5, Time usage: 0.0021229000000033693\
    Method: disk, Time usage: 0.08811370000000807\
    Method: lmdb, Time usage: 0.005510099999995077\
    Method: hdf5, Time usage: 0.0015849999999915099\
    Method: disk, Time usage: 0.8397192000000047\
    Method: lmdb, Time usage: 0.030875000000008868\
    Method: hdf5, Time usage: 0.0026256999999958452\
    Method: disk, Time usage: 8.7503715\
    Method: lmdb, Time usage: 0.2223862999999966\
    Method: hdf5, Time usage: 0.01714979999999855\
    Method: disk, Time usage: 84.8027426\
    Method: lmdb, Time usage: 2.7005553999999847\
    Method: hdf5, Time usage: 0.22156839999999534


Setiap cara penyimpanan akan dicoba menyimpan sebayak 111110 gambar dan
setiap gambar disimpan 5 kali. Dari ketiga cara penyimpanan hdf5
memiliki kemangkusan terbaik. Alasan yang menjadikannya terbaik yakni
untuk setiap percobaan penyimpanan waktu yang diperlukan selalu lebih
kecil dari yang lain. Selain itu, hanya hdf5 yang mana tendensi waktu
penyimpanan setiap percobaan terbilang konstan dibanding lmdb dan disk.

``` python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

![alt text](gambar1.png)
![alt text](gambar2.png)
Terlihat bahwa baik pada grafik pertama HDF5 dan LMDB akan selalu lebih
baik untuk segala ukuran data baik kecil maupun yang besar. Dari grafik
ke 2 png files memimiliki kemangkusan yang terburuk dibandingkan LMDB
dan juga HDF5.

Reading from Disk

Selanjutnya akan diuji seberapa baik ketiga metode dalam membaca data
yang sudah dicoba untuk disimpan olehnya


-Experiment for reading as single image



-Reading from single disk

``` python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

=Reading from single lmdb

``` python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

-Reading from single hdf5

``` python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```

``` python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

Experiment for Reading a Single Image

``` python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

outputnya =>\
    Method: disk, Time usage: 0.010393899999996847\
    Method: lmdb, Time usage: 0.014496699999995144\
    Method: hdf5, Time usage: 0.010247699999979432

Terlihat bahwa lmdb memiliki kemangkusan yang terburuk sedangkan hdf5
yang terbaik. Untuk disk sendiri kemangkusannya tidak terlalu jauh
berbeda dengan lmdb

Reading many images

Adjusting the Code for Many Images

Sama halnya dengan membaca single images dengan ketiga cara, akan tetapi
kali ini gambar yang dibaca ada banyak

``` python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object 
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

experiment for reading many images

``` python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=0,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

outputnya =>\
    Method: disk, No. images: 10, Time usage: 3.000000106112566e-07\
    Method: lmdb, No. images: 10, Time usage: 1.999999312829459e-07\
    Method: hdf5, No. images: 10, Time usage: 2.0000004496978363e-07\
    Method: disk, No. images: 100, Time usage: 3.000000106112566e-07\
    Method: lmdb, No. images: 100, Time usage: 3.000000106112566e-07\
    Method: hdf5, No. images: 100, Time usage: 3.000000106112566e-07\
    Method: disk, No. images: 1000, Time usage: 2.0000004496978363e-07\
    Method: lmdb, No. images: 1000, Time usage: 2.0000004496978363e-07\
    Method: hdf5, No. images: 1000, Time usage: 2.0000004496978363e-07\
    Method: disk, No. images: 10000, Time usage: 2.0000004496978363e-07\
    Method: lmdb, No. images: 10000, Time usage: 2.0000004496978363e-07\
    Method: hdf5, No. images: 10000, Time usage: 3.000000106112566e-07\
    Method: disk, No. images: 100000, Time usage: 3.000000106112566e-07\
    Method: lmdb, No. images: 100000, Time usage: 1.999999312829459e-07\
    Method: hdf5, No. images: 100000, Time usage: 3.000000106112566e-07

Untuk hasil pembacaan banyak images justru LMDB lebih cepat dibandingkan
HDF5 dan disk

``` python
disk_x_r = read_many_timings["disk"]
lmdb_x_r = read_many_timings["lmdb"]
hdf5_x_r = read_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Read time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Log read time",
    log=True,
)
```

``` python
plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r, disk_x, lmdb_x, hdf5_x],
    [
        "Read PNG",
        "Read LMDB",
        "Read HDF5",
        "Write PNG",
        "Write LMDB",
        "Write HDF5",
    ],
    "Number of images",
    "Seconds",
    "Log Store and Read Times",
    log=False,
)
```

![alt text](gambar3.png)
![alt text](gambar4.png)

Dari grafik diketahui bahwa kemampuan membaca gambar oleh HDF5 cenderung naik kemudian konstan. Sedangkan PNG akan terus naik secara linear dimulai dari banyaknya gambar yang diproses. Hal ini tentunya sangat berbedan dengan LMDB yang mana cenderung kostan baik pada pembacaan gambar sedikit sampai banyak sekalipun. Ini berkesusaian pada output waktu eksekusi tadi yang menunjukkan keteraturan waktu eksekusi sepanjang banyaknya gambar yang dibaca oleh LMDB.

![alt text](gambar5.png)

Dari grafik di atas ddapatkan bahwa untuk setiap metode memiliki kecenderungan selisih kecepatan antar read dan write data tekecuali png files yang mana waktu read filesnya jauh lebih lama dariw writenya. Secara keseluruhan dari segi kompleksitas waktu HDF5 dan LMDB jauh lebih unggul dari png files.

``` python
# Memory used in KB
disk_mem = [24, 204, 2004, 20032, 200296]
lmdb_mem = [60, 420, 4000, 39000, 393000]
hdf5_mem = [36, 304, 2900, 29000, 293000]

X = [disk_mem, lmdb_mem, hdf5_mem]

ind = np.arange(3)
width = 0.35

plt.subplots(figsize=(8, 10))
plots = [plt.bar(ind, [row[0] for row in X], width)]
for i in range(1, len(cutoffs)):
    plots.append(
        plt.bar(
            ind, [row[i] for row in X], width, bottom=[row[i - 1] for row in X]
        )
    )

plt.ylabel("Memory in KB")
plt.title("Disk memory used by method")
plt.xticks(ind, ("PNG", "LMDB", "HDF5"))
plt.yticks(np.arange(0, 400000, 100000))

plt.legend(
    [plot[0] for plot in plots], ("10", "100", "1,000", "10,000", "100,000")
)
plt.show()
```
![alt text](gambar6.png)


Meskipun LMDB dan HDF5 mengungguli PNG dalam melakukan pembacaan dan
penulisan terhadapa data, akan tetapi PNG mampu memiliki kompleksitas
penyimpanan yang lebih rendah membuatnya lebih mangkus dari sisi
kompleksitas ruang.

Pemilihan metode untuk penyimpanan dan pembacaan data yakni disk/png
files, LMDB, atau HDF5. HDF5 unggul dalam proses penyimpanan data
sedangakn LMDB unggul dalam proses pembacaan data. Di sisilain disk/png
files memiliki keunggulan yang mengalahkan LMDB dan HDF5 yakni
kehematannya dalam menyimpan datasets bahkan dalam jumlah ratusan ribu
sekalipun.

